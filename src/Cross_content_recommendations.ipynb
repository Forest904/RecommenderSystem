{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing datasets\n",
    "#Books\n",
    "books_file = 'datasets/books_rs/books.csv'\n",
    "df_books = pd.read_csv(books_file)\n",
    "\n",
    "#Movies\n",
    "movies_file = 'datasets/books_rs/movies.csv'\n",
    "df_movies = pd.read_csv(movies_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the two datasets omogeneus.  First reordering.\n",
    "Now we separate the ratings from the actual content, before removing the unnecessary attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindexing columns\n",
    "df_books = df_books.reindex(columns=['title', 'categories', 'authors', 'description', 'ratings_count', 'average_rating', 'published_year', 'subtitle', 'isbn13'])\n",
    "df_movies = df_movies.reindex(columns=['Series_Title', 'Genre', 'Director', 'Overview', 'No_of_Votes', 'IMDB_Rating', 'Released_Year'])\n",
    "\n",
    "#Drop unused columns\n",
    "df_books = df_books.drop(['published_year', 'subtitle', 'isbn13'], axis=1, errors='ignore')\n",
    "df_movies = df_movies.drop(['Released_Year'], axis=1, errors='ignore')\n",
    "\n",
    "#Rename the columns to be the same\n",
    "df_movies.columns = ['title', 'categories', 'authors', 'description', 'ratings_count', 'average_rating']\n",
    "\n",
    "#Add a column to identify the type of content\n",
    "df_books['content_type'] = 'book' \n",
    "df_movies['content_type'] = 'movie'\n",
    "\n",
    "#Save separated ratings and content dataframes for books and movies\n",
    "df_books_ratings = df_books[['title', 'ratings_count', 'average_rating']]\n",
    "df_books_content = df_books.drop(['ratings_count', 'average_rating'], axis=1, errors='ignore')\n",
    "\n",
    "df_movies_ratings = df_movies[['title', 'ratings_count', 'average_rating']]\n",
    "df_movies_content = df_movies.drop(['ratings_count', 'average_rating'], axis=1, errors='ignore')\n",
    "\n",
    "#Normalize the books ratings\n",
    "df_books_ratings.loc[:, 'average_rating'] = df_books_ratings['average_rating'] * 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the two content dataframes, keeping an eye on the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_books_content dimensions: (6810, 5)\n",
      "df_movies_content dimensions: (1000, 5)\n",
      "cross_content dimensions: (7810, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_books_content dimensions:\", df_books_content.shape)\n",
    "print(\"df_movies_content dimensions:\", df_movies_content.shape)\n",
    "cross_content = pd.concat([df_books_content, df_movies_content])\n",
    "print(\"cross_content dimensions:\", cross_content.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we condense all the non title attributes in one TAGS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gilead</td>\n",
       "      <td>Fiction; Marilynne Robinson; A NOVEL THAT READ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Detective and mystery stories; Charles Osborne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The One Tree</td>\n",
       "      <td>American fiction; Stephen R. Donaldson; Volume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Fiction; Sidney Sheldon; A memorable, mesmeriz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Christian life; Clive Staples Lewis; Lewis' wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                               tags\n",
       "0          Gilead  Fiction; Marilynne Robinson; A NOVEL THAT READ...\n",
       "1    Spider's Web  Detective and mystery stories; Charles Osborne...\n",
       "2    The One Tree  American fiction; Stephen R. Donaldson; Volume...\n",
       "3  Rage of angels  Fiction; Sidney Sheldon; A memorable, mesmeriz...\n",
       "4  The Four Loves  Christian life; Clive Staples Lewis; Lewis' wo..."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_content['tags'] = cross_content.apply(lambda row: '; '.join([str(row[col]) for col in cross_content.columns if col != 'title']), axis=1)\n",
    "cross_content = cross_content.drop(['categories', 'authors', 'description', 'content_type'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step saving fuck all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_content.to_csv('cross_content.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if the datasets are omogeneus we can merge and apply preprocessing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
